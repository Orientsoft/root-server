{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRT vs pytorch\n",
    "\n",
    "## common things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from time import time\n",
    "\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = './data/root-test.jpg'\n",
    "test_loops = 100\n",
    "batch_size = 1\n",
    "\n",
    "w = 224\n",
    "h = 224\n",
    "\n",
    "num_classes = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRT test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt\n",
    "\n",
    "from trt_toolkit import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp16_mode = False\n",
    "\n",
    "onnx_file = './score_net.onnx'\n",
    "engine_file = './score_net.trt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trt_logger = trt.Logger(min_severity=trt.tensorrt.Logger.Severity.INFO)\n",
    "\n",
    "engine = create_trt_engine(\n",
    "    trt_logger,\n",
    "    onnx_file,\n",
    "    engine_file,\n",
    "    batch_size=batch_size,\n",
    "    fp16_mode=fp16_mode,\n",
    "    save_engine=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.299279383\n",
      "[[0.9206087]]\n"
     ]
    }
   ],
   "source": [
    "# create context\n",
    "context = engine.create_execution_context()\n",
    "\n",
    "# allocate host buffers\n",
    "inputs, outputs, bindings, stream = allocate_buffers(engine)\n",
    "\n",
    "# prepare data\n",
    "img = cv2.imread(img_path)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img = cv2.resize(img, (w, h))\n",
    "img = img.transpose((2, 0, 1))\n",
    "\n",
    "# normalization\n",
    "img = img / 255.\n",
    "\n",
    "# create batch\n",
    "imgs = np.expand_dims(img, axis=0)\n",
    "imgs = imgs.astype(np.float32)\n",
    "\n",
    "output_shape = (batch_size, num_classes)\n",
    "\n",
    "# infer\n",
    "t0 = cv2.getTickCount()\n",
    "\n",
    "for i in range(test_loops):\n",
    "    inputs[0].host = imgs.reshape(-1)\n",
    "    \n",
    "    outs = infer(\n",
    "        context,\n",
    "        bindings=bindings,\n",
    "        inputs=inputs,\n",
    "        outputs=outputs,\n",
    "        stream=stream\n",
    "    )\n",
    "    \n",
    "    results = post_process(outs[0], output_shape)\n",
    "    \n",
    "infer_time = (cv2.getTickCount() - t0) / cv2.getTickFrequency()\n",
    "\n",
    "print(infer_time)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pytorch test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "from resnet import resnet as score_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_model_path = './data/score_state_dict.pth'\n",
    "device_name = 'cuda:0'\n",
    "\n",
    "W = 224\n",
    "H = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5387946\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(device_name)\n",
    "# create model\n",
    "score_net = score_model.resnet50(num_classes=1)\n",
    "score_net.load_state_dict(torch.load(score_model_path, map_location=torch.device(device_name)))\n",
    "score_net = score_net.to(device)\n",
    "score_net.eval()\n",
    "\n",
    "# prepare data\n",
    "img = cv2.imread(img_path)\n",
    "img = cv2.resize(img, (W, H))\n",
    "img = TF.to_tensor(img).unsqueeze(0).to(device)\n",
    "\n",
    "# infer\n",
    "t0 = cv2.getTickCount()\n",
    "with torch.no_grad():\n",
    "    for i in range(test_loops):\n",
    "        output = score_net(img)\n",
    "infer_time = (cv2.getTickCount() - t0) / cv2.getTickFrequency()\n",
    "\n",
    "print(infer_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9206]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (chromo-score)",
   "language": "python",
   "name": "chromo-score"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
