{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# openvino vs pytorch\n",
    "\n",
    "## common things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from time import time\n",
    "\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = './data/root-test.jpg'\n",
    "test_loops = 100\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## openvino test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openvino.inference_engine import IECore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "do NOT scale in model since VPU OP is not accurate enough (at least for regression)\n",
    "\n",
    "convert model with:\n",
    "python mo.py --input_model score_net.onnx --data_type FP16\n",
    "\n",
    "for PIL.Image, convert model with:\n",
    "python mo.py --input_model score_net.onnx --reverse_input_channels --data_type FP16\n",
    "'''\n",
    "\n",
    "model_xml = 'score_net.xml'\n",
    "model_bin = os.path.splitext(model_xml)[0] + '.bin'\n",
    "#device = 'CPU'\n",
    "#device = 'MYRIAD'\n",
    "device = 'MULTI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CPU', 'GNA', 'MYRIAD.1.1-ma2480', 'MYRIAD.1.2-ma2480']\n",
      "MYRIAD\n",
      "[1, 3, 224, 224]\n",
      "0.775584101\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "ie = IECore()\n",
    "\n",
    "print(ie.available_devices)\n",
    "\n",
    "model = ie.read_network(model_xml, model_bin)\n",
    "\n",
    "input_layer_name = next(iter(model.inputs))\n",
    "out_layer_name = next(iter(model.outputs))\n",
    "\n",
    "dev_count = 0\n",
    "\n",
    "'''\n",
    "if device == 'MULTI':\n",
    "    for dev in ie.available_devices:\n",
    "        if 'MYRIAD' in dev:\n",
    "            print(dev_count, dev)\n",
    "            device = '{}{}{}'.format(device, ':' if dev_count==0 else ',', dev)\n",
    "            dev_count += 1\n",
    "print(device)\n",
    "'''\n",
    "\n",
    "exec_model = ie.load_network(model, device)\n",
    "\n",
    "# prepare data\n",
    "n, c, h, w = model.inputs[input_layer_name].shape\n",
    "print(model.inputs[input_layer_name].shape)\n",
    "\n",
    "img = cv2.imread(img_path)\n",
    "img = cv2.resize(img, (w, h))\n",
    "img = img.transpose((2, 0, 1))\n",
    "\n",
    "img = img / 255.\n",
    "\n",
    "# infer\n",
    "reqs = []\n",
    "\n",
    "t0 = cv2.getTickCount()\n",
    "for i in range(test_loops):\n",
    "    output = exec_model.infer(inputs={input_layer_name: img})\n",
    "    '''\n",
    "    reqs.append(exec_model.start_async(\n",
    "        request_id=0,\n",
    "        inputs={input_layer_name: img}\n",
    "    ))\n",
    "    \n",
    "exec_model.wait(num_requests=test_loops)\n",
    "'''\n",
    "infer_time = (cv2.getTickCount() - t0) / cv2.getTickFrequency()\n",
    "\n",
    "print(infer_time)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CPU', 'GNA', 'MYRIAD.1.1-ma2480', 'MYRIAD.1.2-ma2480']\n",
      "2\n",
      "[1, 3, 224, 224]\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "{'Gemm_179': array([[0.9145508]], dtype=float32)}\n",
      "3.890544237\n"
     ]
    }
   ],
   "source": [
    "# multi device experiment\n",
    "\n",
    "# create model\n",
    "ie = IECore()\n",
    "\n",
    "print(ie.available_devices)\n",
    "\n",
    "model = ie.read_network(model_xml, model_bin)\n",
    "\n",
    "input_layer_name = next(iter(model.inputs))\n",
    "out_layer_name = next(iter(model.outputs))\n",
    "\n",
    "exec_models = []\n",
    "\n",
    "if device == 'MULTI':\n",
    "    for dev in ie.available_devices:\n",
    "        if 'MYRIAD' in dev:\n",
    "            exec_models.append(ie.load_network(model, dev))\n",
    "print(len(exec_models))\n",
    "\n",
    "\n",
    "# prepare data\n",
    "n, c, h, w = model.inputs[input_layer_name].shape\n",
    "print(model.inputs[input_layer_name].shape)\n",
    "\n",
    "img = cv2.imread(img_path)\n",
    "img = cv2.resize(img, (w, h))\n",
    "img = img.transpose((2, 0, 1))\n",
    "\n",
    "img = img / 255.\n",
    "\n",
    "reqs = []\n",
    "\n",
    "# infer\n",
    "t0 = cv2.getTickCount()\n",
    "\n",
    "for i in range(test_loops):\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        for m in exec_models:\n",
    "            rid = m.get_idle_request_id()\n",
    "            if rid > -1:\n",
    "                reqs.append(m.start_async(request_id=rid, inputs={input_layer_name: img}))\n",
    "                done = True\n",
    "                break\n",
    "\n",
    "for req in reqs:\n",
    "    req.wait(-1)\n",
    "    print(req.outputs)\n",
    "    \n",
    "infer_time = (cv2.getTickCount() - t0) / cv2.getTickFrequency()\n",
    "\n",
    "print(infer_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pytorch test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "from resnet import resnet as score_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_model_path = './data/score_state_dict.pth'\n",
    "device_name = 'cuda:0'\n",
    "\n",
    "W = 224\n",
    "H = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.182976663\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(device_name)\n",
    "# create model\n",
    "score_net = score_model.resnet50(num_classes=1)\n",
    "score_net.load_state_dict(torch.load(score_model_path, map_location=torch.device(device_name)))\n",
    "score_net = score_net.to(device)\n",
    "score_net.eval()\n",
    "\n",
    "# prepare data\n",
    "img = cv2.imread(img_path)\n",
    "img = cv2.resize(img, (W, H))\n",
    "img = TF.to_tensor(img).unsqueeze(0).to(device)\n",
    "\n",
    "# infer\n",
    "t0 = cv2.getTickCount()\n",
    "with torch.no_grad():\n",
    "    for i in range(test_loops):\n",
    "        output = score_net(img)\n",
    "infer_time = (cv2.getTickCount() - t0) / cv2.getTickFrequency()\n",
    "\n",
    "print(infer_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9206]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (chromo-score)",
   "language": "python",
   "name": "chromo-score"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
